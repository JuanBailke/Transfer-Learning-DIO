{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD3bwRWHf0babwDnPtBXNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanBailke/Transfer-Learning-DIO/blob/main/Transfer_Learning_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xp_qJzy23rYz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixa o ZIP oficial\n",
        "!curl -L -o caltech-101.zip \"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\"\n",
        "\n",
        "# Descompacta o ZIP em pasta local\n",
        "!unzip caltech-101.zip\n",
        "\n",
        "# Extrai o .tar.gz que est√° dentro da pasta caltech-101\n",
        "!tar -xf caltech-101/101_ObjectCategories.tar.gz\n",
        "\n",
        "# Remove o ZIP\n",
        "!rm caltech-101.zip\n",
        "\n",
        "# Lista as pastas\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM1wPEHJcbAO",
        "outputId": "bf2d8088-5aeb-4f61-d25c-5aa4843899c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   476  100   476    0     0    935      0 --:--:-- --:--:-- --:--:--   935\n",
            "100  131M  100  131M    0     0  22.3M      0  0:00:05  0:00:05 --:--:-- 29.4M\n",
            "Archive:  caltech-101.zip\n",
            "   creating: caltech-101/\n",
            "  inflating: __MACOSX/._caltech-101  \n",
            "  inflating: caltech-101/101_ObjectCategories.tar.gz  \n",
            "  inflating: __MACOSX/caltech-101/._101_ObjectCategories.tar.gz  \n",
            "  inflating: caltech-101/show_annotation.m  \n",
            "  inflating: __MACOSX/caltech-101/._show_annotation.m  \n",
            "  inflating: caltech-101/Annotations.tar  \n",
            "  inflating: __MACOSX/caltech-101/._Annotations.tar  \n",
            "101_ObjectCategories  caltech-101  __MACOSX  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = '101_ObjectCategories'\n",
        "exclude = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
        "train_split, val_split = 0.7, 0.15\n",
        "\n",
        "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
        "categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
        "\n",
        "print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTuHLG1xz8CS",
        "outputId": "3eb39669-e9c9-48b3-f3b1-a54a894f7339"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['101_ObjectCategories/panda', '101_ObjectCategories/kangaroo', '101_ObjectCategories/electric_guitar', '101_ObjectCategories/schooner', '101_ObjectCategories/lotus', '101_ObjectCategories/elephant', '101_ObjectCategories/pigeon', '101_ObjectCategories/beaver', '101_ObjectCategories/umbrella', '101_ObjectCategories/car_side', '101_ObjectCategories/cannon', '101_ObjectCategories/joshua_tree', '101_ObjectCategories/helicopter', '101_ObjectCategories/buddha', '101_ObjectCategories/llama', '101_ObjectCategories/pizza', '101_ObjectCategories/dolphin', '101_ObjectCategories/yin_yang', '101_ObjectCategories/anchor', '101_ObjectCategories/cougar_body', '101_ObjectCategories/gramophone', '101_ObjectCategories/octopus', '101_ObjectCategories/grand_piano', '101_ObjectCategories/garfield', '101_ObjectCategories/platypus', '101_ObjectCategories/stegosaurus', '101_ObjectCategories/scissors', '101_ObjectCategories/dragonfly', '101_ObjectCategories/Leopards', '101_ObjectCategories/windsor_chair', '101_ObjectCategories/scorpion', '101_ObjectCategories/brontosaurus', '101_ObjectCategories/crocodile', '101_ObjectCategories/soccer_ball', '101_ObjectCategories/pagoda', '101_ObjectCategories/mayfly', '101_ObjectCategories/crocodile_head', '101_ObjectCategories/hedgehog', '101_ObjectCategories/chair', '101_ObjectCategories/mandolin', '101_ObjectCategories/ferry', '101_ObjectCategories/butterfly', '101_ObjectCategories/ewer', '101_ObjectCategories/bonsai', '101_ObjectCategories/pyramid', '101_ObjectCategories/flamingo_head', '101_ObjectCategories/laptop', '101_ObjectCategories/cougar_face', '101_ObjectCategories/headphone', '101_ObjectCategories/ibis', '101_ObjectCategories/trilobite', '101_ObjectCategories/hawksbill', '101_ObjectCategories/cellphone', '101_ObjectCategories/inline_skate', '101_ObjectCategories/sea_horse', '101_ObjectCategories/rooster', '101_ObjectCategories/accordion', '101_ObjectCategories/wheelchair', '101_ObjectCategories/water_lilly', '101_ObjectCategories/brain', '101_ObjectCategories/cup', '101_ObjectCategories/euphonium', '101_ObjectCategories/ketch', '101_ObjectCategories/barrel', '101_ObjectCategories/ant', '101_ObjectCategories/rhino', '101_ObjectCategories/tick', '101_ObjectCategories/flamingo', '101_ObjectCategories/minaret', '101_ObjectCategories/binocular', '101_ObjectCategories/chandelier', '101_ObjectCategories/lobster', '101_ObjectCategories/snoopy', '101_ObjectCategories/watch', '101_ObjectCategories/camera', '101_ObjectCategories/emu', '101_ObjectCategories/strawberry', '101_ObjectCategories/saxophone', '101_ObjectCategories/ceiling_fan', '101_ObjectCategories/nautilus', '101_ObjectCategories/metronome', '101_ObjectCategories/starfish', '101_ObjectCategories/bass', '101_ObjectCategories/crab', '101_ObjectCategories/crayfish', '101_ObjectCategories/sunflower', '101_ObjectCategories/wrench', '101_ObjectCategories/stop_sign', '101_ObjectCategories/gerenuk', '101_ObjectCategories/okapi', '101_ObjectCategories/wild_cat', '101_ObjectCategories/revolver', '101_ObjectCategories/lamp', '101_ObjectCategories/menorah', '101_ObjectCategories/dollar_bill', '101_ObjectCategories/dalmatian', '101_ObjectCategories/stapler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to load image and return it and input vector\n",
        "def get_image(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return img, x"
      ],
      "metadata": {
        "id": "uxD2BTQ229Nm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for c, category in enumerate(categories):\n",
        "    images = [os.path.join(dp, f) for dp, dn, filenames\n",
        "              in os.walk(category) for f in filenames\n",
        "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "    for img_path in images:\n",
        "        img, x = get_image(img_path)\n",
        "        data.append({'x':np.array(x[0]), 'y':c})\n",
        "\n",
        "# count the number of classes\n",
        "num_classes = len(categories)"
      ],
      "metadata": {
        "id": "dQPlMFyr3C76"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "EJJnM0mO3Fdb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_val = int(train_split * len(data))\n",
        "idx_test = int((train_split + val_split) * len(data))\n",
        "train = data[:idx_val]\n",
        "val = data[idx_val:idx_test]\n",
        "test = data[idx_test:]"
      ],
      "metadata": {
        "id": "Bouy_ipy3HTu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
        "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
        "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOJdZBeU3JBz",
        "outputId": "0cdb5ca6-bcfb-4557-9a57-88ff8ba45b1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[72, 73, 3, 62, 92, 8, 73, 83, 67, 65, 85, 81, 13, 84, 90, 73, 88, 24, 22, 12, 57, 14, 48, 20, 71, 62, 9, 64, 86, 68, 42, 70, 68, 46, 83, 79, 93, 43, 27, 14, 35, 10, 13, 64, 11, 92, 43, 17, 87, 42, 93, 90, 28, 14, 14, 85, 46, 56, 12, 48, 42, 43, 96, 49, 91, 22, 47, 25, 73, 17, 24, 63, 1, 73, 61, 66, 43, 54, 59, 8, 71, 65, 82, 69, 44, 85, 50, 49, 82, 73, 3, 28, 46, 93, 93, 14, 21, 85, 89, 8, 5, 62, 37, 50, 85, 84, 32, 84, 30, 84, 89, 77, 62, 52, 63, 92, 1, 25, 9, 9, 85, 33, 79, 68, 48, 8, 5, 72, 95, 14, 11, 11, 25, 53, 46, 73, 53, 56, 9, 60, 19, 31, 32, 81, 18, 81, 14, 26, 31, 33, 17, 44, 15, 17, 71, 37, 27, 51, 50, 73, 27, 2, 48, 65, 42, 93, 28, 92, 57, 83, 72, 20, 8, 57, 5, 76, 75, 1, 57, 61, 32, 18, 0, 37, 43, 46, 62, 9, 85, 93, 2, 28, 16, 58, 70, 12, 61, 48, 78, 60, 2, 28, 13, 70, 92, 49, 50, 13, 39, 76, 3, 13, 73, 26, 51, 73, 57, 23, 46, 59, 82, 91, 46, 15, 60, 23, 59, 91, 51, 8, 18, 68, 87, 24, 62, 54, 12, 37, 46, 30, 43, 50, 71, 73, 62, 93, 8, 78, 19, 73, 73, 47, 28, 68, 50, 18, 3, 93, 62, 83, 43, 2, 28, 49, 59, 28, 76, 10, 57, 63, 91, 12, 89, 38, 84, 92, 1, 55, 78, 11, 33, 93, 21, 43, 37, 2, 15, 25, 81, 22, 15, 32, 0, 42, 49, 22, 67, 37, 14, 28, 20, 40, 41, 17, 9, 54, 51, 36, 89, 50, 62, 29, 45, 37, 20, 95, 5, 28, 36, 85, 57, 86, 95, 43, 57, 11, 13, 82, 5, 30, 23, 73, 59, 28, 59, 1, 28, 82, 6, 47, 11, 77, 50, 28, 95, 52, 23, 1, 27, 5, 60, 12, 2, 9, 59, 26, 73, 14, 33, 54, 59, 68, 47, 46, 54, 62, 30, 40, 1, 41, 49, 87, 87, 70, 9, 34, 46, 31, 30, 11, 75, 49, 66, 39, 66, 29, 67, 58, 61, 74, 77, 33, 66, 62, 91, 69, 34, 30, 81, 82, 36, 90, 59, 47, 86, 56, 96, 67, 8, 88, 18, 26, 65, 57, 22, 40, 90, 77, 76, 79, 30, 85, 41, 62, 28, 15, 55, 51, 57, 19, 39, 70, 32, 22, 14, 26, 39, 47, 76, 44, 85, 67, 3, 82, 84, 73, 13, 3, 31, 43, 94, 12, 74, 30, 82, 60, 21, 38, 70, 92, 28, 63, 8, 16, 42, 10, 96, 49, 60, 81, 41, 31, 30, 85, 58, 41, 17, 47, 69, 73, 20, 88, 2, 73, 10, 83, 5, 76, 53, 16, 18, 15, 54, 5, 32, 32, 45, 62, 50, 62, 49, 93, 28, 62, 8, 49, 66, 12, 53, 82, 4, 60, 76, 19, 4, 27, 75, 11, 31, 43, 68, 48, 61, 67, 48, 7, 86, 60, 72, 42, 86, 33, 44, 31, 27, 23, 32, 39, 34, 82, 18, 65, 48, 49, 30, 67, 22, 38, 29, 74, 13, 50, 84, 34, 48, 11, 9, 86, 81, 36, 11, 28, 31, 28, 85, 32, 73, 31, 2, 41, 73, 44, 70, 14, 9, 88, 31, 17, 63, 7, 78, 90, 55, 54, 23, 42, 73, 44, 81, 73, 60, 63, 61, 22, 72, 65, 1, 95, 70, 39, 39, 89, 30, 4, 81, 38, 72, 43, 80, 94, 28, 15, 78, 59, 41, 96, 31, 62, 41, 9, 74, 33, 32, 40, 40, 49, 44, 47, 81, 88, 37, 1, 93, 53, 21, 61, 74, 89, 77, 83, 59, 54, 92, 73, 15, 40, 41, 35, 52, 73, 68, 61, 81, 1, 2, 49, 54, 14, 68, 13, 70, 35, 33, 84, 56, 41, 33, 77, 14, 88, 1, 95, 73, 9, 48, 14, 70, 62, 41, 73, 62, 9, 93, 22, 59, 38, 81, 92, 85, 47, 51, 85, 85, 73, 89, 6, 56, 43, 14, 18, 91, 75, 29, 41, 4, 3, 62, 40, 9, 28, 61, 8, 71, 27, 45, 48, 27, 91, 11, 30, 65, 46, 43, 3, 32, 65, 79, 21, 38, 19, 61, 1, 96, 42, 43, 7, 33, 11, 42, 26, 28, 28, 75, 42, 9, 51, 67, 85, 1, 43, 58, 22, 45, 35, 75, 78, 77, 60, 4, 40, 30, 47, 79, 37, 40, 37, 94, 72, 1, 84, 58, 2, 69, 10, 41, 5, 65, 95, 73, 37, 50, 59, 14, 62, 79, 52, 81, 46, 1, 43, 23, 14, 60, 51, 74, 6, 70, 63, 49, 52, 62, 29, 51, 50, 73, 93, 22, 36, 10, 84, 86, 28, 58, 28, 19, 92, 45, 29, 76, 67, 10, 83, 81, 68, 91, 51, 70, 86, 10, 29, 6, 96, 63, 91, 49, 12, 49, 60, 25, 95, 94, 73, 4, 39, 57, 13, 48, 18, 33, 68, 95, 73, 91, 24, 95, 94, 15, 35, 74, 5, 26, 62, 96, 41, 59, 34, 72, 46, 3, 44, 8, 22, 73, 34, 14, 14, 96, 49, 35, 94, 33, 49, 12, 51, 28, 70, 29, 11, 52, 79, 21, 25, 57, 40, 17, 73, 4, 47, 38, 51, 54, 38, 40, 28, 64, 51, 36, 41, 70, 12, 42, 73, 65, 71, 51, 9, 17, 0, 68, 52, 41, 58, 22, 68, 42, 30, 38, 56, 72, 40, 28, 93]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_val = x_val.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# convert labels to one-hot vectors\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "mvpocsQX3LAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "print(\"finished loading %d images from %d categories\"%(len(data), num_classes))\n",
        "print(\"train / validation / test split: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
        "print(\"training data shape: \", x_train.shape)\n",
        "print(\"training labels shape: \", y_train.shape)\n"
      ],
      "metadata": {
        "id": "MuX3ZMtW3Mxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "idx = [int(len(images) * random.random()) for i in range(8)]\n",
        "imgs = [image.load_img(images[i], target_size=(224, 224)) for i in idx]\n",
        "concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)\n",
        "plt.figure(figsize=(16,4))\n",
        "plt.imshow(concat_image)"
      ],
      "metadata": {
        "id": "NUyaKPfX3RBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the network\n",
        "model = Sequential()\n",
        "print(\"Input dimensions: \",x_train.shape[1:])\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jiF3RhMS3RjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model to use categorical cross-entropy loss function and adadelta optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "h3bnNaf13V5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_acc\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OPsO-Zje3XvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "HMdmnUOR3YQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
        "vgg.summary()"
      ],
      "metadata": {
        "id": "X-e6FSFq3aSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a reference to VGG's input layer\n",
        "inp = vgg.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
        "out = new_classification_layer(vgg.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_new = Model(inp, out)\n"
      ],
      "metadata": {
        "id": "IXY31L4B3gH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_new.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_new.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_new.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "metadata": {
        "id": "2A8xS19y3gkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model_new.fit(x_train, y_train,\n",
        "                         batch_size=128,\n",
        "                         epochs=10,\n",
        "                         validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "yZCoCl8f3iVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"val_loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"validation loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_acc\"])\n",
        "ax2.plot(history2.history[\"val_acc\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yNsIHfYy3kVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "tnPyKgoX3nYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, x = get_image('101_ObjectCategories/airplanes/image_0003.jpg')\n",
        "probabilities = model_new.predict([x])"
      ],
      "metadata": {
        "id": "M_QvUoeW3p-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}