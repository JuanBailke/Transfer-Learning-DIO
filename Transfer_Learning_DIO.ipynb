{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0Z1PhkAhgTMScER1larob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanBailke/Transfer-Learning-DIO/blob/main/Transfer_Learning_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning com TensorFlow/Keras no Colab - Gatos vs Cachorros\n",
        "\n",
        "### Projeto criado para Treinamento de Redes Neurais com Transfer Learning do bootcamp [BairesDev - Machine Learning Training](https://web.dio.me/track/bairesdev-machine-learning-training)"
      ],
      "metadata": {
        "id": "lAc9FO_7coYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Download e extração do dataset"
      ],
      "metadata": {
        "id": "kgK4b8y-doVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xp_qJzy23rYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a14fda7-9262-4ac8-baa0-b3f3ba8c3a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-03 15:47:26--  https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 184.30.24.206, 2a02:26f0:6d00:39f::317f, 2a02:26f0:6d00:3b6::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|184.30.24.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘cats_and_dogs.zip’\n",
            "\n",
            "cats_and_dogs.zip   100%[===================>] 786.67M   216MB/s    in 3.7s    \n",
            "\n",
            "2025-08-03 15:47:30 (212 MB/s) - ‘cats_and_dogs.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O cats_and_dogs.zip \"https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\"\n",
        "!unzip -q cats_and_dogs.zip -d dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Organização das pastas (train / val split)"
      ],
      "metadata": {
        "id": "LUBjdGERduug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "from PIL import Image\n",
        "\n",
        "src = 'dataset/PetImages'\n",
        "dst = 'dataset_split'\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "for label in ['Cat', 'Dog']:\n",
        "    files = os.listdir(os.path.join(src, label))\n",
        "    files = [f for f in files if os.path.isfile(os.path.join(src, label, f))]\n",
        "    random.shuffle(files)\n",
        "    split = int(0.8 * len(files))\n",
        "    for phase, subset in [('train', files[:split]), ('val', files[split:])]:\n",
        "        outdir = os.path.join(dst, phase, label)\n",
        "        os.makedirs(outdir, exist_ok=True)\n",
        "        for fname in subset:\n",
        "            fpath = os.path.join(src, label, fname)\n",
        "            try:\n",
        "                with Image.open(fpath) as img:\n",
        "                  img.verify() # verifica se o arquivo é uma imagem válida\n",
        "                shutil.copy(fpath, outdir)\n",
        "            except Exception as e:\n",
        "                print(f\"Imagem inválida removida: {fpath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM1wPEHJcbAO",
        "outputId": "4facbdff-6004-4157-8af3-fb8b4cc4589f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem inválida removida: dataset/PetImages/Cat/Thumbs.db\n",
            "Imagem inválida removida: dataset/PetImages/Cat/666.jpg\n",
            "Imagem inválida removida: dataset/PetImages/Dog/Thumbs.db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem inválida removida: dataset/PetImages/Dog/11702.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_imagens_invalidas(pasta):\n",
        "    for root, _, files in os.walk(pasta):\n",
        "        for f in files:\n",
        "            path = os.path.join(root, f)\n",
        "            try:\n",
        "                with Image.open(path) as img:\n",
        "                    img.verify()\n",
        "            except:\n",
        "                print(\"Removendo imagem inválida:\", path)\n",
        "                os.remove(path)\n",
        "\n",
        "remover_imagens_invalidas(\"dataset_split\")"
      ],
      "metadata": {
        "id": "lM90NWG4twMC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Importação de bibliotecas"
      ],
      "metadata": {
        "id": "BW6V1bSLd_8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "GTuHLG1xz8CS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preparação dos dados"
      ],
      "metadata": {
        "id": "7MLaUrtveF77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "uxD2BTQ229Nm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "dirs = {\n",
        "    'train': 'dataset_split/train',\n",
        "    'val': 'dataset_split/val'\n",
        "}\n",
        "\n",
        "data_train = datagen_train.flow_from_directory(\n",
        "    dirs['train'],\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "data_val = datagen_val.flow_from_directory(\n",
        "    dirs['val'],\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQPlMFyr3C76",
        "outputId": "75ef00b3-c7be-4d15-8a0c-79aa13354f90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19996 images belonging to 2 classes.\n",
            "Found 5002 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Modelo com transfer learning (MobileNetV2)"
      ],
      "metadata": {
        "id": "64FYhqJ1eVmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "KxCoQZzXeWoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f92a81-3265-43ca-98e9-be0d10bfc053"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Treinamento"
      ],
      "metadata": {
        "id": "1nIGMLGbeaI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    data_train,\n",
        "    validation_data=data_val,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzXVpA7DebEH",
        "outputId": "27174e76-015a-47de-9e7e-02c110bcfc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m291/625\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m9:42\u001b[0m 2s/step - accuracy: 0.8980 - loss: 0.2319"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Avaliação e visualização"
      ],
      "metadata": {
        "id": "eJk3SlFHedww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.title('Acurácia por época')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bsRPNRwAeeiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Predição de exemplo"
      ],
      "metadata": {
        "id": "1UPKERbReiYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = data_val.filepaths[0]\n",
        "img = image.load_img(sample_path, target_size=IMG_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "pred = model.predict(img_array)[0][0]\n",
        "print(f\"Imagem: {sample_path}\\nPrevisão: {'Dog' if pred > 0.5 else 'Cat'} (confiança: {pred:.2f})\")"
      ],
      "metadata": {
        "id": "Du8BqYlTejO7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}